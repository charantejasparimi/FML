{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC8dYCAvw8YK",
        "outputId": "30ce98db-0051-482d-905f-f80ce2b7cbe2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removepunctuations** "
      ],
      "metadata": {
        "id": "lwSPqhG3bt0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aa=\"Hi hello. we are is the in ground \"\n",
        "a=aa.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4z8agc17sTa",
        "outputId": "346f7e75-d2c0-468b-d364-e65dfcdbb364"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi hello we are is the in ground \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To remove stop words**"
      ],
      "metadata": {
        "id": "TEDmEXwqb_fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b=set(stopwords.words(\"english\"))\n",
        "c=word_tokenize(a)\n",
        "print(\"sentence :\",aa)\n",
        "print(\"removed punctuations :\",a)\n",
        "print(\"list of strings :\",c)\n",
        "print(\"stop words in set  :\",b)\n",
        "d=[x for x in c if not x.lower() in b ]\n",
        "print(\"after noise removal : \",d)\n",
        "e=' ' #delimiter in between list we can place what we want I placed white space\n",
        "print(e.join(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAjmawoXbqEM",
        "outputId": "8cb68d52-6a66-47e6-fb8f-eee208822df2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence : Hi hello. we are is the in ground \n",
            "removed punctuations : Hi hello we are is the in ground \n",
            "list of strings : ['Hi', 'hello', 'we', 'are', 'is', 'the', 'in', 'ground']\n",
            "stop words in set  : {'wouldn', 'such', 'is', 'now', 'hasn', 'me', 'on', 'did', 'how', 'into', 'be', 'both', 'these', 'to', 'which', 'no', 'you', 'so', 'ain', 'theirs', 'shan', 'an', 'further', \"hadn't\", 'and', 'a', 'll', 'this', 'hers', 'he', 'more', 'before', \"aren't\", 'doesn', 'hadn', 'those', \"won't\", 'are', 'then', 'doing', 'their', \"shan't\", 'was', 'until', 'out', 'them', 'why', 'for', \"didn't\", 'not', 'his', \"isn't\", 'whom', \"you'd\", 'than', \"wasn't\", 'mightn', 'won', 'off', 'will', 'with', 'needn', 'during', 'she', 'because', 'itself', 'once', 'am', 'what', 'some', 'ourselves', 't', \"it's\", 'if', 'don', 'had', 'have', 'm', 'against', \"couldn't\", 'haven', 'isn', 'where', 'who', 'below', 'each', 'when', 'should', \"that'll\", 'wasn', 'above', 'aren', 'at', \"hasn't\", 'that', 've', \"weren't\", \"mightn't\", \"she's\", 'its', 'having', 'same', 'it', 'by', 'themselves', \"you're\", 'between', \"you've\", 'own', \"you'll\", \"should've\", 'over', 'any', 'while', 'there', 'again', 'too', 'up', 'd', 'didn', 'shouldn', 'my', \"don't\", 'herself', \"haven't\", 'has', 'our', 'being', 'as', \"doesn't\", \"mustn't\", 'very', 'of', 'been', 're', \"shouldn't\", 'ours', 'him', 'ma', 'they', 's', 'through', 'in', 'about', 'most', 'few', 'do', 'other', 'yourself', 'your', 'here', 'after', 'down', 'nor', 'the', 'couldn', 'can', \"wouldn't\", 'her', 'yours', 'only', 'or', 'from', 'just', 'y', \"needn't\", 'we', 'i', 'o', 'myself', 'yourselves', 'himself', 'weren', 'does', 'were', 'but', 'under', 'all', 'mustn'}\n",
            "after noise removal :  ['Hi', 'hello', 'ground']\n",
            "Hi hello ground\n"
          ]
        }
      ]
    }
  ]
}